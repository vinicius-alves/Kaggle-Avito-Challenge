{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "37c92f91-7569-4b03-a82a-236dff6fef9a",
    "_uuid": "fe1ee0c221546a5e4757bdfe512c1c39ee157654",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 37,
        "hidden": false,
        "row": 0,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "\n",
    "# Ideas for Generating Image Features and Measuring Image Quality\n",
    "\n",
    "<br>\n",
    "\n",
    "![](https://i.imgur.com/84TEdoa.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "[Avito](https://www.kaggle.com/c/avito-demand-prediction) is Russia's largest Advertisment firm. The quality of the advertisement image significantly affects the demand volume on an item. For both advertisers and Avito, it is important to use authentic high quality images. In this kernel, I have implemented some ideas which can be used to create new features related to images. These features are an indicatory factors about the Image Quality. Following is the list of feature ideas:  \n",
    "\n",
    "\n",
    "### 1. Dullness : Is the Image Very Dull ?   \n",
    "    \n",
    "   1.1 Image Dullness Score\n",
    "\n",
    "### 2. Whiteness : Is the Image Very White ?  \n",
    "   2.1 Image Whiteness Score  \n",
    "    \n",
    "### 3. Uniformity : Is the Image too Uniform ?\n",
    "   3.1 Average Pixel Width\n",
    "\n",
    "### 4. Colors : What are the top colors used in the Image ? \n",
    "   4.1 Dominant Color of the Image   \n",
    "   4.2 Average Color of the Image\n",
    "\n",
    "### 5. Dimensions : Is the Image too Large or too Small ?  \n",
    "   5.1 Width of the Image    \n",
    "   5.2 Height of the Image   \n",
    "   5.3 Size of the Image    \n",
    "\n",
    "### 6. Blurrness : Is the Image Too Blurry ?   \n",
    "   6.1 Width of the Image      \n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "ccdc873b-d98f-40c8-939c-9725a74f262c",
    "_kg_hide-input": true,
    "_uuid": "5768a3c8f6f633403efdcce8398ac3eaa74ebde1",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from scipy.stats import itemfreq\n",
    "from skimage import feature\n",
    "from PIL import Image as IMG\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import operator\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import multiprocessing\n",
    "from threading import Thread\n",
    "\n",
    "images_path = './images/'\n",
    "imgs = os.listdir(images_path)\n",
    "imgs_names = list(filter(lambda image_name: image_name.endswith('jpg') ,imgs))\n",
    "\n",
    "num_imgs = len(imgs_names)\n",
    "\n",
    "\n",
    "feature_dullness            = np.zeros(num_imgs)\n",
    "feature_whiteness           = np.zeros(num_imgs)\n",
    "feature_average_pixel_width = np.zeros(num_imgs)\n",
    "feature_dominant_red        = np.zeros(num_imgs)\n",
    "feature_dominant_green      = np.zeros(num_imgs)\n",
    "feature_dominant_blue       = np.zeros(num_imgs)\n",
    "feature_average_red         = np.zeros(num_imgs)\n",
    "feature_average_green       = np.zeros(num_imgs)\n",
    "feature_average_blue        = np.zeros(num_imgs)\n",
    "feature_width               = np.zeros(num_imgs)\n",
    "feature_height              = np.zeros(num_imgs)\n",
    "feature_size                = np.zeros(num_imgs)\n",
    "feature_blurrness_score     = np.zeros(num_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "imgs_names_splitted = np.array_split(imgs_names, num_cores)\n",
    "num_partitions = num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_analysis(img):\n",
    "    # obtain the color palatte of the image \n",
    "    palatte = defaultdict(int)\n",
    "    for pixel in img.getdata():\n",
    "        palatte[pixel] += 1\n",
    "    \n",
    "    # sort the colors present in the image \n",
    "    sorted_x = sorted(palatte.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    light_shade, dark_shade, shade_count, pixel_limit = 0, 0, 0, 25\n",
    "    for i, x in enumerate(sorted_x[:pixel_limit]):\n",
    "        if all(xx <= 20 for xx in x[0][:3]): ## dull : too much darkness \n",
    "            dark_shade += x[1]\n",
    "        if all(xx >= 240 for xx in x[0][:3]): ## bright : too much whiteness \n",
    "            light_shade += x[1]\n",
    "        shade_count += x[1]\n",
    "        \n",
    "    light_percent = round((float(light_shade)/shade_count)*100, 2)\n",
    "    dark_percent = round((float(dark_shade)/shade_count)*100, 2)\n",
    "    return light_percent, dark_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_color_analysis(img):\n",
    "    #img = img.convert(\"RGB\")\n",
    "    \n",
    "    # cut the images into two halves as complete average may give bias results\n",
    "    size = img.size\n",
    "    halves = (size[0]/2, size[1]/2)\n",
    "    im1 = img.crop((0, 0, size[0], halves[1]))\n",
    "    im2 = img.crop((0, halves[1], size[0], size[1]))\n",
    "\n",
    "    try:\n",
    "        light_percent1, dark_percent1 = color_analysis(im1)\n",
    "        light_percent2, dark_percent2 = color_analysis(im2)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "    light_percent = (light_percent1 + light_percent2)/2 \n",
    "    dark_percent  = (dark_percent1 + dark_percent2)/2 \n",
    "    \n",
    "    return dark_percent , light_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pixel_width(img):    \n",
    "    im_array = np.asarray(img.convert(mode='L'))\n",
    "    edges_sigma1 = feature.canny(im_array, sigma=3)\n",
    "    apw = (float(np.sum(edges_sigma1)) / (img.size[0]*img.size[1]))\n",
    "    return apw*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dominant_color(img):\n",
    "    arr = np.float32(img)\n",
    "    pixels = arr.reshape((-1, 3))\n",
    "\n",
    "    n_colors = 5\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, .1)\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    _, labels, centroids = cv2.kmeans(pixels, n_colors, None, criteria, 10, flags)\n",
    "\n",
    "    palette = np.uint8(centroids)\n",
    "    quantized = palette[labels.flatten()]\n",
    "    quantized = quantized.reshape(img.shape)\n",
    "\n",
    "    dominant_color = palette[np.argmax(itemfreq(labels)[:, -1])]\n",
    "    return dominant_color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_color(img):\n",
    "    average_color = [img[:, :, i].mean() for i in range(img.shape[-1])]\n",
    "    return average_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSize(file_path):\n",
    "    st = os.stat(file_path)\n",
    "    return st.st_size\n",
    "\n",
    "def getDimensions(img):\n",
    "    img_size = img.size\n",
    "    return img_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blurrness_score(img):\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    fm = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(id_thread):\n",
    "    imgs_names_th = imgs_names_splitted[id_thread]\n",
    "    num_imgs_th   = len(imgs_names_th)\n",
    "    \n",
    "    print ('thread '+str(id_thread)+' started')\n",
    "    \n",
    "    start_point = 0\n",
    "    for i in range(num_partitions):\n",
    "        if(i<id_thread):\n",
    "            start_point += len(imgs_names_splitted[i])\n",
    "    \n",
    "    for i in range(num_imgs_th):\n",
    "        \n",
    "        if(id_thread == 0 and (i*100)/num_imgs_th % 10 == 0):\n",
    "            print('Progress: '+str((i*100)/num_imgs_th)+'%\\n')\n",
    "        \n",
    "        img_path = images_path+imgs_names_th[i]\n",
    "        img      = IMG.open(img_path)\n",
    "        img_cv2  = cv2.imread(img_path)\n",
    "        j = start_point+i\n",
    "        \n",
    "        feature_size[j] = getSize(img_path)\n",
    "        \n",
    "        dimensions = getDimensions(img)\n",
    "        feature_width[j]  = dimensions[0]\n",
    "        feature_height[j] = dimensions[1]\n",
    "        \n",
    "        dark_percent, light_percent = perform_color_analysis(img)\n",
    "        feature_dullness [j]          = dark_percent\n",
    "        feature_whiteness[j]          = light_percent\n",
    "        \n",
    "        \n",
    "        feature_average_pixel_width[j] = average_pixel_width(img)\n",
    "        \n",
    "        img = None\n",
    "        \n",
    "        feature_blurrness_score[j] = get_blurrness_score(img_cv2)\n",
    "        \n",
    "        '''\n",
    "        dominant_color = get_dominant_color(img_cv2)\n",
    "        feature_dominant_red[j]   = dominant_color[0]/255\n",
    "        feature_dominant_green[j] = dominant_color[1]/255\n",
    "        feature_dominant_blue[j]  = dominant_color[2]/255\n",
    "        '''\n",
    "        \n",
    "        average_color = get_average_color(img_cv2)\n",
    "        feature_average_red[j]   = average_color[0]/255\n",
    "        feature_average_green[j] = average_color[1]/255\n",
    "        feature_average_blue[j]  = average_color[2]/255\n",
    "        \n",
    "        #remove .jpg suffix\n",
    "        #imgs_names_th[i] = re.sub('\\.jpg$', '', imgs_names_th[i])\n",
    "        \n",
    "    print ('thread '+str(id_thread)+' finished')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 started\n",
      "Progress: 0.0%\n",
      "\n",
      "thread 1 started\n",
      "thread 2 started\n",
      "thread 3 started\n",
      "Progress: 10.0%\n",
      "\n",
      "Progress: 20.0%\n",
      "\n",
      "Progress: 30.0%\n",
      "\n",
      "Progress: 40.0%\n",
      "\n",
      "Progress: 50.0%\n",
      "\n",
      "Progress: 60.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "threads = [Thread(target=compute,args=(id_thread,)) for id_thread in range(num_cores)]\n",
    "[thread.start() for thread in threads]\n",
    "[thread.join() for thread in threads]\n",
    "end = time.time()\n",
    "\n",
    "'''\n",
    "benchmark\n",
    "print('\\ntime processing parallel: '+str(\"%.2f\" % (end - start))+'s\\n')\n",
    "\n",
    "start = time.time()\n",
    "compute(0)\n",
    "compute(1)\n",
    "compute(2)\n",
    "compute(3)\n",
    "end = time.time()\n",
    "\n",
    "print('\\ntime processing serial: '+str(\"%.2f\" % (end - start))+'s')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "\n",
    "#remove .jpg suffix\n",
    "imgs_names = list(map(lambda image_name:  re.sub('\\.jpg$', '', image_name),imgs_names))\n",
    "\n",
    "d = {\n",
    "     'id'    : imgs_names,\n",
    "     'width' : feature_width,\n",
    "     'height': feature_height,\n",
    "     'size'  : feature_size,\n",
    "     'dullness' : feature_dullness, \n",
    "     'whiteness': feature_whiteness,\n",
    "     #'dominant_red'  : feature_dominant_red,\n",
    "     #'dominant_green': feature_dominant_green,\n",
    "     #'dominant_blue' : feature_dominant_blue,\n",
    "     'average_red'   : feature_average_red,\n",
    "     'average_green' : feature_average_green,\n",
    "     'average_blue'  : feature_average_blue,\n",
    "     'average_pixel_width' : feature_average_pixel_width,\n",
    "     'blurrness_score'     : feature_blurrness_score \n",
    "    }\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "df.to_csv('train_jpg.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
