{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento das Imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "37c92f91-7569-4b03-a82a-236dff6fef9a",
    "_uuid": "fe1ee0c221546a5e4757bdfe512c1c39ee157654",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 37,
        "hidden": false,
        "row": 0,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "ccdc873b-d98f-40c8-939c-9725a74f262c",
    "_kg_hide-input": true,
    "_uuid": "5768a3c8f6f633403efdcce8398ac3eaa74ebde1",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from scipy.stats import itemfreq\n",
    "from skimage import feature\n",
    "from PIL import Image as IMG\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import operator\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import multiprocessing\n",
    "from threading import Thread\n",
    "\n",
    "#Obtém a lista de arquivos de imagens no diretório imagens\n",
    "images_path = './images/'\n",
    "imgs = os.listdir(images_path)\n",
    "imgs_names = list(filter(lambda image_name: image_name.endswith('jpg') ,imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot identify image file './images/4f029e2a00e892aa2cac27d98b52ef8b13d91471f613c8d3c38e3f29d4da0b0c.jpg'\n",
      "4f029e2a00e892aa2cac27d98b52ef8b13d91471f613c8d3c38e3f29d4da0b0c.jpg removed from processing\n",
      "\n",
      "cannot identify image file './images/8513a91e55670c709069b5f85e12a59095b802877715903abef16b7a6f306e58.jpg'\n",
      "8513a91e55670c709069b5f85e12a59095b802877715903abef16b7a6f306e58.jpg removed from processing\n",
      "\n",
      "\n",
      "time looking for corrupted images: 0.08s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "imgs_names_splitted = np.array_split(imgs_names, num_cores)\n",
    "num_partitions = num_cores\n",
    "\n",
    "# Busca por imagens corrompidas\n",
    "# Há cerca de 12 imagens corrompidas nos dados do kaggle\n",
    "def search_corrupted_images(id_thread):\n",
    "\n",
    "    imgs_names_th = imgs_names_splitted[id_thread]\n",
    "    num_imgs_th   = len(imgs_names_th)\n",
    "\n",
    "    start_point = 0\n",
    "    for i in range(num_partitions):\n",
    "        if(i<id_thread):\n",
    "            start_point += len(imgs_names_splitted[i])\n",
    "\n",
    "    for i in range(num_imgs_th):\n",
    "        try:\n",
    "            IMG.open(images_path+imgs_names_th[i])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(imgs_names[start_point+i] + ' removed from processing\\n')\n",
    "            imgs_names[start_point+i] = \"\"\n",
    "\n",
    "# Paralelizando busca de imagens corrompidas\n",
    "start = time.time()\n",
    "threads = [Thread(target=search_corrupted_images,args=(id_thread,)) for id_thread in range(num_cores)]\n",
    "[thread.start() for thread in threads]\n",
    "[thread.join() for thread in threads]   \n",
    "end = time.time()\n",
    "\n",
    "imgs_names = list(filter(lambda image_name: image_name != '' ,imgs_names))\n",
    "\n",
    "print('\\ntime looking for corrupted images: '+str(\"%.2f\" % (end - start))+'s\\n')\n",
    "\n",
    "#update imgs_names_splitted\n",
    "imgs_names_splitted = np.array_split(imgs_names, num_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando estruturas de dados para armazenar resultado do processamento de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = len(imgs_names)\n",
    "\n",
    "feature_dullness            = np.zeros(num_imgs)\n",
    "feature_whiteness           = np.zeros(num_imgs)\n",
    "feature_average_pixel_width = np.zeros(num_imgs)\n",
    "feature_dominant_red        = np.zeros(num_imgs)\n",
    "feature_dominant_green      = np.zeros(num_imgs)\n",
    "feature_dominant_blue       = np.zeros(num_imgs)\n",
    "feature_average_red         = np.zeros(num_imgs)\n",
    "feature_average_green       = np.zeros(num_imgs)\n",
    "feature_average_blue        = np.zeros(num_imgs)\n",
    "feature_width               = np.zeros(num_imgs)\n",
    "feature_height              = np.zeros(num_imgs)\n",
    "feature_size                = np.zeros(num_imgs)\n",
    "feature_blurrness_score     = np.zeros(num_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos para processamento \n",
    "Métodos para calcular features das imagens fornecidas pelo usuário sban. \n",
    "Foram produzidas versões otimizadas para estes, tornando o processamento mais rápido\n",
    "Ref.: https://www.kaggle.com/shivamb/ideas-for-image-features-and-image-quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_analysis(img):\n",
    "    # obtain the color palatte of the image \n",
    "    palatte = defaultdict(int)\n",
    "    for pixel in img.getdata():\n",
    "        palatte[pixel] += 1\n",
    "    \n",
    "    # sort the colors present in the image \n",
    "    sorted_x = sorted(palatte.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    light_shade, dark_shade, shade_count, pixel_limit = 0, 0, 0, 25\n",
    "    for i, x in enumerate(sorted_x[:pixel_limit]):\n",
    "        if all(xx <= 20 for xx in x[0][:3]): ## dull : too much darkness \n",
    "            dark_shade += x[1]\n",
    "        if all(xx >= 240 for xx in x[0][:3]): ## bright : too much whiteness \n",
    "            light_shade += x[1]\n",
    "        shade_count += x[1]\n",
    "        \n",
    "    light_percent = round((float(light_shade)/shade_count)*100, 2)\n",
    "    dark_percent = round((float(dark_shade)/shade_count)*100, 2)\n",
    "    return light_percent, dark_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_color_analysis(img):\n",
    "    #img = img.convert(\"RGB\")\n",
    "    \n",
    "    # cut the images into two halves as complete average may give bias results\n",
    "    size = img.size\n",
    "    halves = (size[0]/2, size[1]/2)\n",
    "    im1 = img.crop((0, 0, size[0], halves[1]))\n",
    "    im2 = img.crop((0, halves[1], size[0], size[1]))\n",
    "\n",
    "    try:\n",
    "        light_percent1, dark_percent1 = color_analysis(im1)\n",
    "        light_percent2, dark_percent2 = color_analysis(im2)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "    light_percent = (light_percent1 + light_percent2)/2 \n",
    "    dark_percent  = (dark_percent1 + dark_percent2)/2 \n",
    "    \n",
    "    return dark_percent , light_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pixel_width(img):    \n",
    "    im_array = np.asarray(img.convert(mode='L'))\n",
    "    edges_sigma1 = feature.canny(im_array, sigma=3)\n",
    "    apw = (float(np.sum(edges_sigma1)) / (img.size[0]*img.size[1]))\n",
    "    return apw*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dominant_color(img):\n",
    "    arr = np.float32(img)\n",
    "    pixels = arr.reshape((-1, 3))\n",
    "\n",
    "    n_colors = 5\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, .1)\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    _, labels, centroids = cv2.kmeans(pixels, n_colors, None, criteria, 10, flags)\n",
    "\n",
    "    palette = np.uint8(centroids)\n",
    "    quantized = palette[labels.flatten()]\n",
    "    quantized = quantized.reshape(img.shape)\n",
    "\n",
    "    dominant_color = palette[np.argmax(itemfreq(labels)[:, -1])]\n",
    "    return dominant_color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_color(img):\n",
    "    average_color = [img[:, :, i].mean() for i in range(img.shape[-1])]\n",
    "    return average_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSize(file_path):\n",
    "    st = os.stat(file_path)\n",
    "    return st.st_size\n",
    "\n",
    "def getDimensions(img):\n",
    "    img_size = img.size\n",
    "    return img_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blurrness_score(img):\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    fm = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método que gera e salva features para as imagens\n",
    "def compute(id_thread):\n",
    "    imgs_names_th = imgs_names_splitted[id_thread]\n",
    "    num_imgs_th   = len(imgs_names_th)\n",
    "    \n",
    "    print ('thread '+str(id_thread)+' started')\n",
    "    \n",
    "    start_point = 0\n",
    "    for i in range(num_partitions):\n",
    "        if(i<id_thread):\n",
    "            start_point += len(imgs_names_splitted[i])\n",
    "    \n",
    "    for i in range(num_imgs_th):\n",
    "        \n",
    "        if(id_thread == 0 and (i*100)/num_imgs_th % 10 == 0):\n",
    "            print('Progress: '+str((i*100)/num_imgs_th)+'%\\n')\n",
    "        \n",
    "        img_path = images_path+imgs_names_th[i]\n",
    "        img      = IMG.open(img_path)\n",
    "        img_cv2  = cv2.imread(img_path)\n",
    "        j = start_point+i\n",
    "        \n",
    "        feature_size[j] = getSize(img_path)\n",
    "        \n",
    "        dimensions = getDimensions(img)\n",
    "        feature_width[j]  = dimensions[0]\n",
    "        feature_height[j] = dimensions[1]\n",
    "        \n",
    "        dark_percent, light_percent = perform_color_analysis(img)\n",
    "        feature_dullness [j]          = dark_percent\n",
    "        feature_whiteness[j]          = light_percent\n",
    "        \n",
    "        \n",
    "        feature_average_pixel_width[j] = average_pixel_width(img)\n",
    "        \n",
    "        img = None\n",
    "        \n",
    "        feature_blurrness_score[j] = get_blurrness_score(img_cv2)\n",
    "        \n",
    "        # Cor dominante removida da análise, pois tem alto custo de processamento\n",
    "        '''\n",
    "        dominant_color = get_dominant_color(img_cv2)\n",
    "        feature_dominant_red[j]   = dominant_color[0]/255\n",
    "        feature_dominant_green[j] = dominant_color[1]/255\n",
    "        feature_dominant_blue[j]  = dominant_color[2]/255\n",
    "        '''\n",
    "        \n",
    "        average_color = get_average_color(img_cv2)\n",
    "        feature_average_red[j]   = average_color[0]/255\n",
    "        feature_average_green[j] = average_color[1]/255\n",
    "        feature_average_blue[j]  = average_color[2]/255\n",
    "        \n",
    "    print ('thread '+str(id_thread)+' finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processando imagens paralelamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 started\n",
      "Progress: 0.0%\n",
      "\n",
      "thread 1 started\n",
      "thread 2 started\n",
      "thread 3 started\n",
      "Progress: 20.0%\n",
      "\n",
      "Progress: 40.0%\n",
      "\n",
      "Progress: 60.0%\n",
      "\n",
      "Progress: 80.0%\n",
      "\n",
      "thread 3 finished\n",
      "thread 0 finished\n",
      "thread 1 finished\n",
      "thread 2 finished\n",
      "\n",
      "time processing parallel: 2.11s\n",
      "\n",
      "thread 0 started\n",
      "Progress: 0.0%\n",
      "\n",
      "Progress: 20.0%\n",
      "\n",
      "Progress: 40.0%\n",
      "\n",
      "Progress: 60.0%\n",
      "\n",
      "Progress: 80.0%\n",
      "\n",
      "thread 0 finished\n",
      "thread 1 started\n",
      "thread 1 finished\n",
      "thread 2 started\n",
      "thread 2 finished\n",
      "thread 3 started\n",
      "thread 3 finished\n",
      "\n",
      "time processing serial: 2.56s\n"
     ]
    }
   ],
   "source": [
    "# Paralelizando o processamento de imagens\n",
    "start = time.time()\n",
    "threads = [Thread(target=compute,args=(id_thread,)) for id_thread in range(num_cores)]\n",
    "[thread.start() for thread in threads]\n",
    "[thread.join() for thread in threads]\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "#benchmark\n",
    "print('\\ntime processing parallel: '+str(\"%.2f\" % (end - start))+'s\\n')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(num_cores):\n",
    "    compute(i)\n",
    "end = time.time()\n",
    "\n",
    "print('\\ntime processing serial: '+str(\"%.2f\" % (end - start))+'s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "\n",
    "#remove .jpg suffix\n",
    "imgs_names = list(map(lambda image_name:  re.sub('\\.jpg$', '', image_name),imgs_names))\n",
    "\n",
    "data = {\n",
    "     'id'    : imgs_names,\n",
    "     'width' : feature_width,\n",
    "     'height': feature_height,\n",
    "     'size'  : feature_size,\n",
    "     'dullness' : feature_dullness, \n",
    "     'whiteness': feature_whiteness,\n",
    "     #'dominant_red'  : feature_dominant_red,\n",
    "     #'dominant_green': feature_dominant_green,\n",
    "     #'dominant_blue' : feature_dominant_blue,\n",
    "     'average_red'   : feature_average_red,\n",
    "     'average_green' : feature_average_green,\n",
    "     'average_blue'  : feature_average_blue,\n",
    "     'average_pixel_width' : feature_average_pixel_width,\n",
    "     'blurrness_score'     : feature_blurrness_score \n",
    "    }\n",
    "\n",
    "columns = [\n",
    "            'id', \n",
    "            'width', \n",
    "            'height',\n",
    "            'size', \n",
    "            'dullness', \n",
    "            'whiteness',\n",
    "            #'dominant_red',\n",
    "            #'dominant_green',\n",
    "            #'dominant_blue',\n",
    "            'average_red', \n",
    "            'average_green',\n",
    "            'average_blue',\n",
    "            'average_pixel_width',\n",
    "            'blurrness_score'\n",
    "                  ]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=data,columns=columns)\n",
    "\n",
    "df.to_csv('train_jpg.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
